# Notes
## AKI
  1. Lee et. al., 2018 [Prediction of Acute Kidney Injury after Liver Transplantation: Machine Learning Approaches vs. Logistic Regression Model](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6262324/)
  2. Burckhardt et al. 2018, [Multi-Trajectory Modeling to Predict Acute Kidney Injury in Chronic Kidney Disease Patients](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6371306/) , AMIA Annu Symp Proc
  3. Adhikari et al., [Improved predictive models for acute kidney injury with IDEA: Intraoperative Data Embedded Analytics](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6448850/)
  4. Zimmerman et al., [Early prediction of acute kidney injury following ICU admission using a multivariate panel of physiological measurements](https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-0733-z)
  5. Tomasev 2019, Nature, [A clinically applicable approach to continuous prediction of future acute kidney injury](https://www.nature.com/articles/s41586-019-1390-1)
  6. Miksch, [Artificial Intelligence for Decision Support: Needs, Possibilities, and Limitations in ICU](https://link.springer.com/chapter/10.1007/978-88-470-2203-4_85)
  7. Cismondi, 2013, [Reducing unnecessary lab testing in the ICU with artificial intelligence](https://www.sciencedirect.com/science/article/pii/S1386505612002420#bib0145)
  8. Choi, 2016, [DoctorAI: Predicting Clinical Events via RNN](http://nematilab.info/bmijc/assets/170607_paper.pdf)
## ODEnet
  1.Schiebinger, 2019, Cell, [Optimal-Transport Analysis of Single-Cell Gene Expression Identifies Developmental Trajectories in Reprogramming](https://www.cell.com/cell/pdf/S0092-8674(19)30039-X.pdf) 
## RL: Collaborative, Interactive, Robotics
  1. Anca Dragon, 2017, 
  [Robot Planning with Mathematical Models of Human State and Action](https://arxiv.org/abs/1705.04226)
    : A summary of work on collaborative and interactive work done at Berkeley
## RL: Intrinsic Reward, Exploration
  1. Savinov et. al., 2018 [Episodic Curiosity through Reachability](https://arxiv.org/abs/1810.02274)
    : Google Brain/ Deepmind/ ETH Zurich work
## RL: Reward Design
  1. Deepmind, NeurIPS, 2018 [Reward learning from human preferences and demonstrations in Atari](https://arxiv.org/pdf/1811.06521.pdf)
  2. 
## DRL, IRL, Imitation Learning 
  1. Deepmind, AAAI 2018 [Deep Q-learning from Demonstrations](https://arxiv.org/abs/1704.03732)
  
## NeurIPS 2018
  1. [End-to-End Differentiable Physics for Learning and Control](https://neurips.cc/media/Slides/nips/2018/220cd(05-09-45)-05-09-55-12624-End-to-End_Diff.pdf); [paper](https://papers.nips.cc/paper/7948-end-to-end-differentiable-physics-for-learning-and-control.pdf)
  2. [Efficient Online Portfolio with Logarithmic Regret] (https://neurips.cc/Conferences/2018/Schedule?showEvent=12624) : number of rounds, stocks and maximum relative ratio; use regularizer to avoid too extreme distribution over stocks, increase the learning rate of worse stocks for faster recovery, restarting to adapt to maximum relative ratio
  3. [Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing](https://neurips.cc/Conferences/2018/Schedule?showEvent=12624):deterministic environment with sparse rewards
  4. 
